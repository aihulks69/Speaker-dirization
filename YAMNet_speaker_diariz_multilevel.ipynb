{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YAMNet_speaker_diariz_multilevel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MXJWxdGyhspKcdxWzrlgSqH7ChoHPw50",
      "authorship_tag": "ABX9TyP9FaSfQVVX8KlpYUapfTGP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQBo4h0TVNzf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "\n",
        "from scipy.io import wavfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iCJ-b0dRjO3",
        "outputId": "64223d8b-681c-4ef8-946b-af3c96194606"
      },
      "source": [
        "import scipy.signal\n",
        "import numpy as np\n",
        "import librosa\n",
        "#from noisereduce.plotting import plot_reduction_steps\n",
        "from tqdm.autonotebook import tqdm\n",
        "import warnings\n",
        "import copy\n",
        "\n",
        "\n",
        "def _stft(y, n_fft, hop_length, win_length, use_tensorflow=False):\n",
        "    if use_tensorflow:\n",
        "        # return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, center=True)\n",
        "        return _stft_tensorflow(y, n_fft, hop_length, win_length)\n",
        "    else:\n",
        "        return librosa.stft(\n",
        "            y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, center=True\n",
        "        )\n",
        "\n",
        "\n",
        "def _istft(y, n_fft, hop_length, win_length, use_tensorflow=False):\n",
        "    if use_tensorflow:\n",
        "        # return librosa.istft(y, hop_length, win_length)\n",
        "        return _istft_tensorflow(y.T, n_fft, hop_length, win_length)\n",
        "    else:\n",
        "        return librosa.istft(y, hop_length, win_length)\n",
        "\n",
        "\n",
        "def _stft_librosa(y, n_fft, hop_length, win_length):\n",
        "    return librosa.stft(\n",
        "        y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, center=True\n",
        "    )\n",
        "\n",
        "\n",
        "def _istft_librosa(y, hop_length, win_length):\n",
        "    return librosa.istft(y, hop_length, win_length)\n",
        "\n",
        "\n",
        "def _stft_tensorflow(y, n_fft, hop_length, win_length):\n",
        "    return (\n",
        "        tf.signal.stft(\n",
        "            y,\n",
        "            win_length,\n",
        "            hop_length,\n",
        "            n_fft,\n",
        "            pad_end=True,\n",
        "            window_fn=tf.signal.hann_window,\n",
        "        )\n",
        "        .numpy()\n",
        "        .T\n",
        "    )\n",
        "\n",
        "\n",
        "def _istft_tensorflow(y, n_fft, hop_length, win_length):\n",
        "    return tf.signal.inverse_stft(\n",
        "        y.astype(np.complex64), win_length, hop_length, n_fft\n",
        "    ).numpy()\n",
        "\n",
        "\n",
        "def _amp_to_db(x):\n",
        "    return librosa.core.amplitude_to_db(x, ref=1.0, amin=1e-20, top_db=80.0)\n",
        "\n",
        "\n",
        "def _db_to_amp(x,):\n",
        "    return librosa.core.db_to_amplitude(x, ref=1.0)\n",
        "\n",
        "\n",
        "def update_pbar(pbar, message):\n",
        "    \"\"\" writes to progress bar\n",
        "    \"\"\"\n",
        "    if pbar is not None:\n",
        "        pbar.set_description(message)\n",
        "        pbar.update(1)\n",
        "\n",
        "\n",
        "def _smoothing_filter(n_grad_freq, n_grad_time):\n",
        "    \"\"\"Generates a filter to smooth the mask for the spectrogram\n",
        "        \n",
        "    Arguments:\n",
        "        n_grad_freq {[type]} -- [how many frequency channels to smooth over with the mask.]\n",
        "        n_grad_time {[type]} -- [how many time channels to smooth over with the mask.]\n",
        "    \"\"\"\n",
        "\n",
        "    smoothing_filter = np.outer(\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_freq + 1, endpoint=False),\n",
        "                np.linspace(1, 0, n_grad_freq + 2),\n",
        "            ]\n",
        "        )[1:-1],\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_time + 1, endpoint=False),\n",
        "                np.linspace(1, 0, n_grad_time + 2),\n",
        "            ]\n",
        "        )[1:-1],\n",
        "    )\n",
        "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
        "    return smoothing_filter\n",
        "\n",
        "\n",
        "def mask_signal(sig_stft, sig_mask):\n",
        "    \"\"\" Reduces amplitude of time/frequency regions of a spectrogram based upon a mask \n",
        "        \n",
        "    Arguments:\n",
        "        sig_stft {[type]} -- spectrogram of signal\n",
        "        sig_mask {[type]} -- mask to apply to signal\n",
        "    \n",
        "    Returns:\n",
        "        sig_stft_amp [type] -- masked signal\n",
        "    \"\"\"\n",
        "    sig_stft_amp = sig_stft * (1 - sig_mask)\n",
        "    return sig_stft_amp\n",
        "\n",
        "\n",
        "def convolve_gaussian(sig_mask, smoothing_filter, use_tensorflow=False):\n",
        "    \"\"\" Convolves a gaussian filter with a mask (or any image)\n",
        "    \n",
        "    Arguments:\n",
        "        sig_mask {[type]} -- The signal mask\n",
        "        smoothing_filter {[type]} -- the filter to convolve\n",
        "    \n",
        "    Keyword Arguments:\n",
        "        use_tensorflow {bool} -- use tensorflow.signal or scipy.signal (default: {False})\n",
        "    \"\"\"\n",
        "    if use_tensorflow:\n",
        "        smoothing_filter = smoothing_filter * (\n",
        "            (np.shape(smoothing_filter)[1] - 1) / 2 + 1\n",
        "        )\n",
        "        smoothing_filter = smoothing_filter[:, :, tf.newaxis, tf.newaxis].astype(\n",
        "            \"float32\"\n",
        "        )\n",
        "        img = sig_mask[:, :, tf.newaxis, tf.newaxis].astype(\"float32\")\n",
        "        return (\n",
        "            tf.nn.conv2d(img, smoothing_filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "            .numpy()\n",
        "            .squeeze()\n",
        "        )\n",
        "    else:\n",
        "        return scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
        "\n",
        "\n",
        "def load_tensorflow(verbose=False):\n",
        "    \"\"\"loads tensorflow if it is available\n",
        "    Used as a backend for fft and convolution\n",
        "    \n",
        "    Returns:\n",
        "        bool -- whether to use tensorflow\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # import tensorflow as tf\n",
        "        globals()[\"tf\"] = __import__(\"tensorflow\")\n",
        "\n",
        "        if verbose:\n",
        "            available_gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "            print(\"GPUs available: {}\".format(available_gpus))\n",
        "        if int(tf.__version__[0]) < 2:\n",
        "            warnings.warn(\n",
        "                \"Tensorflow version is below 2.0, reverting to non-tensorflow backend\"\n",
        "            )\n",
        "            return False\n",
        "    except:\n",
        "        warnings.warn(\n",
        "            \"Tensorflow is not installed, reverting to non-tensorflow backend\"\n",
        "        )\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def reduce_noise(\n",
        "    audio_clip,\n",
        "    noise_clip=None,\n",
        "    n_grad_freq=2,\n",
        "    n_grad_time=4,\n",
        "    n_fft=2048,\n",
        "    win_length=2048,\n",
        "    hop_length=512,\n",
        "    n_std_thresh=1.5,\n",
        "    prop_decrease=1.0,\n",
        "    pad_clipping=True,\n",
        "    use_tensorflow=False,\n",
        "    verbose=False,\n",
        "):\n",
        "    \"\"\"Remove noise from audio based upon a clip containing only noise\n",
        "    Args:\n",
        "        audio_clip (array): Waveform of audio\n",
        "        noise_clip (array): The second parameter.\n",
        "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
        "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
        "        n_fft (int): number audio of frames between STFT columns.\n",
        "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
        "        hop_length (int):number audio of frames between STFT columns.\n",
        "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
        "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
        "        pad_clipping (bool): Pad the signals with zeros to ensure that the reconstructed data is equal length to the data\n",
        "        use_tensorflow (bool): Use tensorflow as a backend for convolution and fft to speed up computation\n",
        "        verbose (bool): Whether to plot the steps of the algorithm\n",
        "    Returns:\n",
        "        array: The recovered signal with noise subtracted\n",
        "    \"\"\"\n",
        "    # load tensorflow if you are using it as a backend\n",
        "    if use_tensorflow:\n",
        "        use_tensorflow = load_tensorflow(verbose)\n",
        "\n",
        "    if verbose:\n",
        "        pbar = tqdm(total=7)\n",
        "    else:\n",
        "        pbar = None\n",
        "\n",
        "    # STFT over signal\n",
        "    update_pbar(pbar, \"STFT on signal\")\n",
        "\n",
        "    # pad signal with zeros to avoid extra frames being clipped if desired\n",
        "    if pad_clipping:\n",
        "        nsamp = len(audio_clip)\n",
        "        audio_clip = np.pad(audio_clip, [0, hop_length], mode=\"constant\")\n",
        "\n",
        "    sig_stft = _stft(\n",
        "        audio_clip, n_fft, hop_length, win_length, use_tensorflow=use_tensorflow\n",
        "    )\n",
        "    # spectrogram of signal in dB\n",
        "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
        "\n",
        "    update_pbar(pbar, \"STFT on noise\")\n",
        "    # STFT over noise\n",
        "    if noise_clip is None:\n",
        "        noise_stft = copy.deepcopy(sig_stft)\n",
        "        noise_stft_db = copy.deepcopy(sig_stft_db)\n",
        "    else:\n",
        "        noise_stft = _stft(\n",
        "            noise_clip, n_fft, hop_length, win_length, use_tensorflow=use_tensorflow\n",
        "        )\n",
        "        noise_stft_db = _amp_to_db(np.abs(noise_stft))  # convert to dB\n",
        "    # Calculate statistics over noise\n",
        "    mean_freq_noise = np.mean(noise_stft_db, axis=1)\n",
        "    std_freq_noise = np.std(noise_stft_db, axis=1)\n",
        "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
        "\n",
        "    update_pbar(pbar, \"Generate mask\")\n",
        "\n",
        "    # calculate the threshold for each frequency/time bin\n",
        "    db_thresh = np.repeat(\n",
        "        np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
        "        np.shape(sig_stft_db)[1],\n",
        "        axis=0,\n",
        "    ).T\n",
        "    # mask if the signal is above the threshold\n",
        "    sig_mask = sig_stft_db < db_thresh\n",
        "    update_pbar(pbar, \"Smooth mask\")\n",
        "    # Create a smoothing filter for the mask in time and frequency\n",
        "    smoothing_filter = _smoothing_filter(n_grad_freq, n_grad_time)\n",
        "\n",
        "    # convolve the mask with a smoothing filter\n",
        "    sig_mask = convolve_gaussian(sig_mask, smoothing_filter, use_tensorflow)\n",
        "\n",
        "    sig_mask = sig_mask * prop_decrease\n",
        "    update_pbar(pbar, \"Apply mask\")\n",
        "    # mask the signal\n",
        "\n",
        "    sig_stft_amp = mask_signal(sig_stft, sig_mask)\n",
        "\n",
        "    update_pbar(pbar, \"Recover signal\")\n",
        "    # recover the signal\n",
        "    recovered_signal = _istft(\n",
        "        sig_stft_amp, n_fft, hop_length, win_length, use_tensorflow=use_tensorflow\n",
        "    )\n",
        "    # fix the recovered signal length if padding signal\n",
        "    if pad_clipping:\n",
        "        recovered_signal = librosa.util.fix_length(recovered_signal, nsamp)\n",
        "\n",
        "    recovered_spec = _amp_to_db(\n",
        "        np.abs(\n",
        "            _stft(\n",
        "                recovered_signal,\n",
        "                n_fft,\n",
        "                hop_length,\n",
        "                win_length,\n",
        "                use_tensorflow=use_tensorflow,\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    if verbose:\n",
        "        plot_reduction_steps(\n",
        "            noise_stft_db,\n",
        "            mean_freq_noise,\n",
        "            std_freq_noise,\n",
        "            noise_thresh,\n",
        "            smoothing_filter,\n",
        "            sig_stft_db,\n",
        "            sig_mask,\n",
        "            recovered_spec,\n",
        "        )\n",
        "    return recovered_signal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkmJkB4WRlOc",
        "outputId": "9592062b-c383-41a7-c7b7-eece3bdd4782"
      },
      "source": [
        "!git clone https://github.com/resemble-ai/Resemblyzer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Resemblyzer'...\n",
            "remote: Enumerating objects: 602, done.\u001b[K\n",
            "remote: Total 602 (delta 0), reused 0 (delta 0), pack-reused 602\u001b[K\n",
            "Receiving objects: 100% (602/602), 101.46 MiB | 37.35 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FG-dCm3RoHF",
        "outputId": "148b8a8c-b36b-4515-813c-29c7a161660a"
      },
      "source": [
        "cd Resemblyzer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Resemblyzer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpJUdC22RrHR",
        "outputId": "4270c714-6bd7-411a-c461-9bd22521d4fb"
      },
      "source": [
        "!pip install webrtcvad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 2.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=72370 sha256=b08f37c7abcdff68a324d33eeefd5073ae2d626e51595bbdcbdd1528a08d578a\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f9/67/a3158d131f57e1c0a7d8d966a707d4a2fb27567a4fe47723ad\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xBQ-VkmTG4i",
        "outputId": "c8d0cf36-7fa8-488e-d0c4-0996a1b17297"
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmd0qgtk61A5"
      },
      "source": [
        "from scipy import signal\n",
        "def ensure_sample_rate(original_sample_rate, waveform,\n",
        "                       desired_sample_rate=16000):\n",
        "  \"\"\"Resample waveform if required.\"\"\"\n",
        "  if original_sample_rate != desired_sample_rate:\n",
        "    desired_length = int(round(float(len(waveform)) /\n",
        "                               original_sample_rate * desired_sample_rate))\n",
        "    waveform = signal.resample(waveform, desired_length)\n",
        "  return desired_sample_rate, waveform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vw0-G3Dj9jK"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "# Load the YAMNET model.\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA5xh9DFuFkG",
        "outputId": "7f312cab-6536-4074-f9e4-7dcf4d3a8363"
      },
      "source": [
        "import os\n",
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from pathlib import Path\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2,random_state=42)\n",
        "PATH = '/content/drive/MyDrive'\n",
        " # Define data path\n",
        "data_path = PATH + '/speech'\n",
        "data_dir_list = os.listdir(data_path)\n",
        "featset=[]\n",
        "labl=[]\n",
        "for dataset in data_dir_list:\n",
        "    img_list=os.listdir(data_path+'/'+ dataset)\n",
        "    print ('Loaded the audio of dataset-'+'{}\\\\n'.format(dataset))\n",
        "    for i in range(0,len(img_list)):\n",
        "      wav_fpath=data_path+'/'+ dataset+'/'+img_list[i]\n",
        "      wav = preprocess_wav(wav_fpath)\n",
        "      recov=reduce_noise(wav)\n",
        "      mp3_file = AudioSegment.from_file(wav_fpath)\n",
        "      mp3_file.export('newSong.wav', format=\"wav\")\n",
        "      wav_data, sample_rate1 = sf.read('newSong.wav', dtype=np.int16)\n",
        "      sample_rate, wav_data = ensure_sample_rate(sample_rate1, recov)\n",
        "      duration = len(wav_data)/sample_rate\n",
        "      waveform = wav_data / tf.int16.max\n",
        "      scores, embeddings, spectrogram = model(waveform)\n",
        "      out=np.array(embeddings)\n",
        "      t=pca.fit_transform(np.transpose(out))\n",
        "      t=np.reshape(t,(t.shape[0]*t.shape[1]))\n",
        "      featset.append(t)\n",
        "      labl.append(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the audio of dataset-Spe2\\n\n",
            "Loaded the audio of dataset-Spe3\\n\n",
            "Loaded the audio of dataset-Spe1\\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJL4pME_hUZt"
      },
      "source": [
        "features=np.array(featset)\n",
        "labels=np.array(labl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XVBoGOTTKoM",
        "outputId": "0eb28c8d-f8e0-480e-bc11-044f1072a854"
      },
      "source": [
        "np.unique(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Spe1', 'Spe2', 'Spe3'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD_a2WM2120M"
      },
      "source": [
        "lab=np.zeros([labels.shape[0]],np.uint8)\n",
        "for i in range(0,labels.shape[0]):\n",
        "  if labels[i]=='Spe1':\n",
        "    lab[i]=0\n",
        "  else:\n",
        "    lab[i]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNMUvnmmTGED",
        "outputId": "8d8bf77c-2185-440f-b516-5c51b36262ca"
      },
      "source": [
        "np.unique(lab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3opT1E452GdR"
      },
      "source": [
        "pickle.dump(pca, open(\"pca_model.pkl\",\"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuwvVHn1nmu9"
      },
      "source": [
        "Classifier model on the VOXConverse dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km1LLsBPSapK"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn. model_selection import train_test_split\n",
        "clf1=RandomForestClassifier()\n",
        "X_train,X_test,y_train,y_test=train_test_split(features,lab,shuffle=True,test_size=0.2)\n",
        "clf1.fit(X_train,y_train)\n",
        "pred=clf1.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QqCKqMQTo-A",
        "outputId": "135c13ff-9469-4100-9809-ba6882c7ee2b"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test,pred))\n",
        "print(confusion_matrix(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.57      0.73         7\n",
            "           1       0.82      1.00      0.90        14\n",
            "\n",
            "    accuracy                           0.86        21\n",
            "   macro avg       0.91      0.79      0.82        21\n",
            "weighted avg       0.88      0.86      0.84        21\n",
            "\n",
            "[[ 4  3]\n",
            " [ 0 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWBogKjGnVxY"
      },
      "source": [
        "**Testing phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpaJQUGbjHyK"
      },
      "source": [
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from pathlib import Path\n",
        "import soundfile as sf\n",
        "#from pydub import AudioSegment\n",
        "\n",
        "#give the file path to your audio file\n",
        "audio_file_path = '/content/drive/MyDrive/BWAI Challenge 2 Dataset/Test Dataset/Test 19.wav'\n",
        "wav_fpath = Path(audio_file_path)\n",
        "\n",
        "wav = preprocess_wav(wav_fpath)\n",
        "recov=reduce_noise(wav)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXPD2V60jNmt"
      },
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Import the .mp3 file\n",
        "mp3_file = AudioSegment.from_file(wav_fpath)\n",
        "\n",
        "# Export the .mp3 file as wav\n",
        "mp3_file.export('newSong.wav', format=\"wav\")\n",
        "wav_data, sample_rate1 = sf.read('newSong.wav', dtype=np.int16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHMANeQmjVCl"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "# Load the model.\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0okV9V_NjY8A"
      },
      "source": [
        "  sample_rate, wav_data = ensure_sample_rate(sample_rate1, recov)\n",
        "  duration = len(wav_data)/sample_rate\n",
        "  waveform = wav_data / tf.int16.max\n",
        "  scores, embeddings, spectrogram = model(waveform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nG5mMEojctZ"
      },
      "source": [
        "spec=np.array(embeddings)\n",
        "out=pca.fit_transform(np.transpose(spec))\n",
        "out=np.reshape(out,(1,out.shape[0]*out.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZsaLHvn4Z5V",
        "outputId": "21df8ea4-44e1-4b57-8808-a6bdda42993f"
      },
      "source": [
        "clf3.predict(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4C4T2I_KAX7"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(clf2, open('model_binary_new.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmo04-FWiBvX"
      },
      "source": [
        "import pickle\n",
        "clf2= pickle.load(open('/content/drive/MyDrive/model_binary_new.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4qYpa3OfXiZ",
        "outputId": "31e7f8f8-e81c-43bf-855d-f3985978e867"
      },
      "source": [
        "import os\n",
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from pathlib import Path\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2,random_state=42)\n",
        "\n",
        "PATH = '/content/drive/MyDrive/BWAI Challenge 2 Dataset'\n",
        " # Define data path\n",
        "data_path = PATH + '/Test Dataset'\n",
        "data_dir_list = os.listdir(data_path)\n",
        "test_featset=[]\n",
        "for dataset in data_dir_list:\n",
        "      wav_fpath=data_path+'/'+ dataset\n",
        "      print(dataset)\n",
        "      wav = preprocess_wav(wav_fpath)\n",
        "      recov=reduce_noise(wav)\n",
        "      mp3_file = AudioSegment.from_file(wav_fpath)\n",
        "      mp3_file.export('newSong.wav', format=\"wav\")\n",
        "      wav_data, sample_rate1 = sf.read('newSong.wav', dtype=np.int16)\n",
        "      sample_rate, wav_data = ensure_sample_rate(sample_rate1, recov)\n",
        "      duration = len(wav_data)/sample_rate\n",
        "      waveform = wav_data / tf.int16.max\n",
        "      scores, embeddings, spectrogram = model(waveform)\n",
        "      out=np.array(embeddings)\n",
        "      t=pca.fit_transform(np.transpose(out))\n",
        "      t=np.reshape(t,(t.shape[0]*t.shape[1]))\n",
        "      #for i in range(len(embeddings)):\n",
        "      #  featset.append(embeddings[i])\n",
        "      #  labl.append(dataset)\n",
        "      test_featset.append(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 17.wav\n",
            "Test 15.wav\n",
            "Test 16.wav\n",
            "Test 11.wav\n",
            "Test 14.wav\n",
            "Test 12.wav\n",
            "Test 1.wav\n",
            "Test 13.wav\n",
            "Test 21.wav\n",
            "Test 25.wav\n",
            "Test 20.wav\n",
            "Test 2.wav\n",
            "Test 23.wav\n",
            "Test 18.wav\n",
            "Test 24.wav\n",
            "Test 19.wav\n",
            "Test 4.wav\n",
            "Test 22.wav\n",
            "Test 3.wav\n",
            "Test 5.wav\n",
            "Test 6.wav\n",
            "Test 8.wav\n",
            "Test 9.wav\n",
            "Test 7.wav\n",
            "Test 10.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i-XQ7nCohIu"
      },
      "source": [
        "test_feats=np.array(test_featset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-YfYhpwpEit"
      },
      "source": [
        "new_feat=np.concatenate([features,test_feats[:7]],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XERgYto3lI"
      },
      "source": [
        "y1=[1,1,1,1,1,1,0]  # Label of first six samples of test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MROx7M4Xn6hy"
      },
      "source": [
        "new_lab=np.concatenate([lab,y1],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAcDS0Pdpg4D"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn. model_selection import train_test_split\n",
        "clf2=RandomForestClassifier()\n",
        "X_train,X_test,y_train,y_test=train_test_split(new_feat,new_lab,shuffle=True,test_size=0.2)\n",
        "clf2.fit(X_train,y_train)\n",
        "pred=clf2.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3JoY8pYphF_",
        "outputId": "9ea4d02a-5e79-49aa-f451-0e3754f662ba"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test,pred))\n",
        "print(confusion_matrix(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.43      0.60         7\n",
            "           1       0.80      1.00      0.89        16\n",
            "\n",
            "    accuracy                           0.83        23\n",
            "   macro avg       0.90      0.71      0.74        23\n",
            "weighted avg       0.86      0.83      0.80        23\n",
            "\n",
            "[[ 3  4]\n",
            " [ 0 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6Yz-OaZiDyS"
      },
      "source": [
        "test_lab=[0,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJNXOQS7hK5z"
      },
      "source": [
        "pred=clf2.predict(test_feats[7:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-SrM_8aiVch",
        "outputId": "66254f6f-55e3-4b3a-c32f-572c54241b01"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM8fBB0Hrud-"
      },
      "source": [
        "t_lab=[1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPpMc37ChQXy",
        "outputId": "f8f679ea-7e77-4028-c493-9657339691b4"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(t_lab,pred))\n",
        "print(confusion_matrix(t_lab,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      1.00      0.33         1\n",
            "           1       1.00      0.76      0.87        17\n",
            "\n",
            "    accuracy                           0.78        18\n",
            "   macro avg       0.60      0.88      0.60        18\n",
            "weighted avg       0.96      0.78      0.84        18\n",
            "\n",
            "[[ 1  0]\n",
            " [ 4 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MJF1UMPpMwc"
      },
      "source": [
        "Second level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4vu74lApPxv"
      },
      "source": [
        "new_feat1=np.concatenate([features[27:],test_feats[:6]],axis=0)\n",
        "y1_1=[0,1,0,0,0,0]  # Label of first six samples of test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxnL8Rtxqg_e"
      },
      "source": [
        "lab=np.zeros([77],np.uint8)\n",
        "for i in range(0,labels.shape[0]):\n",
        "  if labels[i]=='Spe2':\n",
        "    lab[i]=0\n",
        "  elif labels[i]=='Spe3':\n",
        "    lab[i]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neUFpZuXpiP9"
      },
      "source": [
        "new_lab1=np.concatenate([lab,y1_1],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFfSD0tSpngz"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn. model_selection import train_test_split\n",
        "clf3=RandomForestClassifier()\n",
        "X_train,X_test,y_train,y_test=train_test_split(new_feat1,new_lab1,shuffle=True,test_size=0.5)\n",
        "clf3.fit(X_train,y_train)\n",
        "pred=clf3.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMETEDKlppqW",
        "outputId": "fe3691d2-c22f-497e-92ed-8411e4c80d90"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test,pred))\n",
        "print(confusion_matrix(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.65      0.72        26\n",
            "           1       0.57      0.75      0.65        16\n",
            "\n",
            "    accuracy                           0.69        42\n",
            "   macro avg       0.69      0.70      0.69        42\n",
            "weighted avg       0.72      0.69      0.69        42\n",
            "\n",
            "[[17  9]\n",
            " [ 4 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LHk4oIhqALo"
      },
      "source": [
        "t1=test_feats[7:12]\n",
        "t2=test_feats[13:]\n",
        "feat_t=np.concatenate([t1,t2],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNSDbc-TpsXY"
      },
      "source": [
        "pred=clf3.predict(feat_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi76b7yksgjn",
        "outputId": "5e91d71c-09a6-4d04-b0f1-c72243a85610"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9iGZPYxpuxA"
      },
      "source": [
        "t_lab=[0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeQLDYwrpxG3"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(t_lab,pred))\n",
        "print(confusion_matrix(t_lab,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGVXHtWYwZ8w"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(clf3, open('model_multi_new.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOYbShdFlPA4"
      },
      "source": [
        "import pickle\n",
        "clf3= pickle.load(open('/content/drive/MyDrive/model_multi_new.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}