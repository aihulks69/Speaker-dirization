{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YAMNET for binary.ipynb",
      "provenance": [],
      "mount_file_id": "1X0tG9KvD1C4I7jCzCFgG8gFKuj86C88x",
      "authorship_tag": "ABX9TyOnIr/7xms7tRPBb122n7vr"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcEboo36Bqf_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "\n",
        "from scipy.io import wavfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF2g3S9HC2LP"
      },
      "source": [
        "Audio denosing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUrcxQBlBsuv"
      },
      "source": [
        "import scipy.signal\n",
        "import numpy as np\n",
        "import librosa\n",
        "#from noisereduce.plotting import plot_reduction_steps\n",
        "from tqdm.autonotebook import tqdm\n",
        "import warnings\n",
        "import copy\n",
        "\n",
        "\n",
        "def _stft(y, n_fft, hop_length, win_length, use_tensorflow=False):\n",
        "    if use_tensorflow:\n",
        "        # return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, center=True)\n",
        "        return _stft_tensorflow(y, n_fft, hop_length, win_length)\n",
        "    else:\n",
        "        return librosa.stft(\n",
        "            y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, center=True\n",
        "        )\n",
        "\n",
        "\n",
        "def _istft(y, n_fft, hop_length, win_length, use_tensorflow=False):\n",
        "    if use_tensorflow:\n",
        "        # return librosa.istft(y, hop_length, win_length)\n",
        "        return _istft_tensorflow(y.T, n_fft, hop_length, win_length)\n",
        "    else:\n",
        "        return librosa.istft(y, hop_length, win_length)\n",
        "\n",
        "\n",
        "def _stft_librosa(y, n_fft, hop_length, win_length):\n",
        "    return librosa.stft(\n",
        "        y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, center=True\n",
        "    )\n",
        "\n",
        "\n",
        "def _istft_librosa(y, hop_length, win_length):\n",
        "    return librosa.istft(y, hop_length, win_length)\n",
        "\n",
        "\n",
        "def _stft_tensorflow(y, n_fft, hop_length, win_length):\n",
        "    return (\n",
        "        tf.signal.stft(\n",
        "            y,\n",
        "            win_length,\n",
        "            hop_length,\n",
        "            n_fft,\n",
        "            pad_end=True,\n",
        "            window_fn=tf.signal.hann_window,\n",
        "        )\n",
        "        .numpy()\n",
        "        .T\n",
        "    )\n",
        "\n",
        "\n",
        "def _istft_tensorflow(y, n_fft, hop_length, win_length):\n",
        "    return tf.signal.inverse_stft(\n",
        "        y.astype(np.complex64), win_length, hop_length, n_fft\n",
        "    ).numpy()\n",
        "\n",
        "\n",
        "def _amp_to_db(x):\n",
        "    return librosa.core.amplitude_to_db(x, ref=1.0, amin=1e-20, top_db=80.0)\n",
        "\n",
        "\n",
        "def _db_to_amp(x,):\n",
        "    return librosa.core.db_to_amplitude(x, ref=1.0)\n",
        "\n",
        "\n",
        "def update_pbar(pbar, message):\n",
        "    \"\"\" writes to progress bar\n",
        "    \"\"\"\n",
        "    if pbar is not None:\n",
        "        pbar.set_description(message)\n",
        "        pbar.update(1)\n",
        "\n",
        "\n",
        "def _smoothing_filter(n_grad_freq, n_grad_time):\n",
        "    \"\"\"Generates a filter to smooth the mask for the spectrogram\n",
        "        \n",
        "    Arguments:\n",
        "        n_grad_freq {[type]} -- [how many frequency channels to smooth over with the mask.]\n",
        "        n_grad_time {[type]} -- [how many time channels to smooth over with the mask.]\n",
        "    \"\"\"\n",
        "\n",
        "    smoothing_filter = np.outer(\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_freq + 1, endpoint=False),\n",
        "                np.linspace(1, 0, n_grad_freq + 2),\n",
        "            ]\n",
        "        )[1:-1],\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_time + 1, endpoint=False),\n",
        "                np.linspace(1, 0, n_grad_time + 2),\n",
        "            ]\n",
        "        )[1:-1],\n",
        "    )\n",
        "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
        "    return smoothing_filter\n",
        "\n",
        "\n",
        "def mask_signal(sig_stft, sig_mask):\n",
        "    \"\"\" Reduces amplitude of time/frequency regions of a spectrogram based upon a mask \n",
        "        \n",
        "    Arguments:\n",
        "        sig_stft {[type]} -- spectrogram of signal\n",
        "        sig_mask {[type]} -- mask to apply to signal\n",
        "    \n",
        "    Returns:\n",
        "        sig_stft_amp [type] -- masked signal\n",
        "    \"\"\"\n",
        "    sig_stft_amp = sig_stft * (1 - sig_mask)\n",
        "    return sig_stft_amp\n",
        "\n",
        "\n",
        "def convolve_gaussian(sig_mask, smoothing_filter, use_tensorflow=False):\n",
        "    \"\"\" Convolves a gaussian filter with a mask (or any image)\n",
        "    \n",
        "    Arguments:\n",
        "        sig_mask {[type]} -- The signal mask\n",
        "        smoothing_filter {[type]} -- the filter to convolve\n",
        "    \n",
        "    Keyword Arguments:\n",
        "        use_tensorflow {bool} -- use tensorflow.signal or scipy.signal (default: {False})\n",
        "    \"\"\"\n",
        "    if use_tensorflow:\n",
        "        smoothing_filter = smoothing_filter * (\n",
        "            (np.shape(smoothing_filter)[1] - 1) / 2 + 1\n",
        "        )\n",
        "        smoothing_filter = smoothing_filter[:, :, tf.newaxis, tf.newaxis].astype(\n",
        "            \"float32\"\n",
        "        )\n",
        "        img = sig_mask[:, :, tf.newaxis, tf.newaxis].astype(\"float32\")\n",
        "        return (\n",
        "            tf.nn.conv2d(img, smoothing_filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "            .numpy()\n",
        "            .squeeze()\n",
        "        )\n",
        "    else:\n",
        "        return scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
        "\n",
        "\n",
        "def load_tensorflow(verbose=False):\n",
        "    \"\"\"loads tensorflow if it is available\n",
        "    Used as a backend for fft and convolution\n",
        "    \n",
        "    Returns:\n",
        "        bool -- whether to use tensorflow\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # import tensorflow as tf\n",
        "        globals()[\"tf\"] = __import__(\"tensorflow\")\n",
        "\n",
        "        if verbose:\n",
        "            available_gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "            print(\"GPUs available: {}\".format(available_gpus))\n",
        "        if int(tf.__version__[0]) < 2:\n",
        "            warnings.warn(\n",
        "                \"Tensorflow version is below 2.0, reverting to non-tensorflow backend\"\n",
        "            )\n",
        "            return False\n",
        "    except:\n",
        "        warnings.warn(\n",
        "            \"Tensorflow is not installed, reverting to non-tensorflow backend\"\n",
        "        )\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def reduce_noise(\n",
        "    audio_clip,\n",
        "    noise_clip=None,\n",
        "    n_grad_freq=2,\n",
        "    n_grad_time=4,\n",
        "    n_fft=2048,\n",
        "    win_length=2048,\n",
        "    hop_length=512,\n",
        "    n_std_thresh=1.5,\n",
        "    prop_decrease=1.0,\n",
        "    pad_clipping=True,\n",
        "    use_tensorflow=False,\n",
        "    verbose=False,\n",
        "):\n",
        "    \"\"\"Remove noise from audio based upon a clip containing only noise\n",
        "    Args:\n",
        "        audio_clip (array): Waveform of audio\n",
        "        noise_clip (array): The second parameter.\n",
        "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
        "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
        "        n_fft (int): number audio of frames between STFT columns.\n",
        "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
        "        hop_length (int):number audio of frames between STFT columns.\n",
        "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
        "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
        "        pad_clipping (bool): Pad the signals with zeros to ensure that the reconstructed data is equal length to the data\n",
        "        use_tensorflow (bool): Use tensorflow as a backend for convolution and fft to speed up computation\n",
        "        verbose (bool): Whether to plot the steps of the algorithm\n",
        "    Returns:\n",
        "        array: The recovered signal with noise subtracted\n",
        "    \"\"\"\n",
        "    # load tensorflow if you are using it as a backend\n",
        "    if use_tensorflow:\n",
        "        use_tensorflow = load_tensorflow(verbose)\n",
        "\n",
        "    if verbose:\n",
        "        pbar = tqdm(total=7)\n",
        "    else:\n",
        "        pbar = None\n",
        "\n",
        "    # STFT over signal\n",
        "    update_pbar(pbar, \"STFT on signal\")\n",
        "\n",
        "    # pad signal with zeros to avoid extra frames being clipped if desired\n",
        "    if pad_clipping:\n",
        "        nsamp = len(audio_clip)\n",
        "        audio_clip = np.pad(audio_clip, [0, hop_length], mode=\"constant\")\n",
        "\n",
        "    sig_stft = _stft(\n",
        "        audio_clip, n_fft, hop_length, win_length, use_tensorflow=use_tensorflow\n",
        "    )\n",
        "    # spectrogram of signal in dB\n",
        "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
        "\n",
        "    update_pbar(pbar, \"STFT on noise\")\n",
        "    # STFT over noise\n",
        "    if noise_clip is None:\n",
        "        noise_stft = copy.deepcopy(sig_stft)\n",
        "        noise_stft_db = copy.deepcopy(sig_stft_db)\n",
        "    else:\n",
        "        noise_stft = _stft(\n",
        "            noise_clip, n_fft, hop_length, win_length, use_tensorflow=use_tensorflow\n",
        "        )\n",
        "        noise_stft_db = _amp_to_db(np.abs(noise_stft))  # convert to dB\n",
        "    # Calculate statistics over noise\n",
        "    mean_freq_noise = np.mean(noise_stft_db, axis=1)\n",
        "    std_freq_noise = np.std(noise_stft_db, axis=1)\n",
        "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
        "\n",
        "    update_pbar(pbar, \"Generate mask\")\n",
        "\n",
        "    # calculate the threshold for each frequency/time bin\n",
        "    db_thresh = np.repeat(\n",
        "        np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
        "        np.shape(sig_stft_db)[1],\n",
        "        axis=0,\n",
        "    ).T\n",
        "    # mask if the signal is above the threshold\n",
        "    sig_mask = sig_stft_db < db_thresh\n",
        "    update_pbar(pbar, \"Smooth mask\")\n",
        "    # Create a smoothing filter for the mask in time and frequency\n",
        "    smoothing_filter = _smoothing_filter(n_grad_freq, n_grad_time)\n",
        "\n",
        "    # convolve the mask with a smoothing filter\n",
        "    sig_mask = convolve_gaussian(sig_mask, smoothing_filter, use_tensorflow)\n",
        "\n",
        "    sig_mask = sig_mask * prop_decrease\n",
        "    update_pbar(pbar, \"Apply mask\")\n",
        "    # mask the signal\n",
        "\n",
        "    sig_stft_amp = mask_signal(sig_stft, sig_mask)\n",
        "\n",
        "    update_pbar(pbar, \"Recover signal\")\n",
        "    # recover the signal\n",
        "    recovered_signal = _istft(\n",
        "        sig_stft_amp, n_fft, hop_length, win_length, use_tensorflow=use_tensorflow\n",
        "    )\n",
        "    # fix the recovered signal length if padding signal\n",
        "    if pad_clipping:\n",
        "        recovered_signal = librosa.util.fix_length(recovered_signal, nsamp)\n",
        "\n",
        "    recovered_spec = _amp_to_db(\n",
        "        np.abs(\n",
        "            _stft(\n",
        "                recovered_signal,\n",
        "                n_fft,\n",
        "                hop_length,\n",
        "                win_length,\n",
        "                use_tensorflow=use_tensorflow,\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    if verbose:\n",
        "        plot_reduction_steps(\n",
        "            noise_stft_db,\n",
        "            mean_freq_noise,\n",
        "            std_freq_noise,\n",
        "            noise_thresh,\n",
        "            smoothing_filter,\n",
        "            sig_stft_db,\n",
        "            sig_mask,\n",
        "            recovered_spec,\n",
        "        )\n",
        "    return recovered_signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7qb87UpEe2L",
        "outputId": "7d4c64cf-84d0-40c1-dc78-c378545912da"
      },
      "source": [
        "!pip install webrtcvad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 51 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 66 kB 3.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=72372 sha256=59bc44c10603eef196f72a36696b5e6a66ce0287dac9edddab181e90b9534106\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f9/67/a3158d131f57e1c0a7d8d966a707d4a2fb27567a4fe47723ad\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DUItyyHBuv4",
        "outputId": "ef84b0c3-481c-4c83-b008-a76235e367fa"
      },
      "source": [
        "!git clone https://github.com/resemble-ai/Resemblyzer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Resemblyzer'...\n",
            "remote: Enumerating objects: 602, done.\u001b[K\n",
            "remote: Total 602 (delta 0), reused 0 (delta 0), pack-reused 602\u001b[K\n",
            "Receiving objects: 100% (602/602), 101.46 MiB | 30.96 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTYp8WCqBw4Z",
        "outputId": "be5fb2cd-64a3-499e-cc70-a48ab0c0d61f"
      },
      "source": [
        "cd Resemblyzer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Resemblyzer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE47t5-2C8U-"
      },
      "source": [
        "Input 'TEST' audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6_Stf0fByXe"
      },
      "source": [
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from pathlib import Path\n",
        "import soundfile as sf\n",
        "#from pydub import AudioSegment\n",
        "\n",
        "#give the file path to your audio file\n",
        "audio_file_path = '...pathfile...'\n",
        "wav_fpath = Path(audio_file_path)\n",
        "\n",
        "wav = preprocess_wav(wav_fpath)\n",
        "recov=reduce_noise(wav)\n",
        "#encoder = VoiceEncoder(\"cpu\")\n",
        "#_, cont_embeds, wav_splits = encoder.embed_utterance(recov, return_partials=True, rate=16)\n",
        "#print(cont_embeds.shape)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCf5BhzsB0v6",
        "outputId": "ccf99a9b-7ece-49d0-8754-f24efba6c6e2"
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrZEITJ0C_ji"
      },
      "source": [
        "Get the sample rate of input wav"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7bnE03wB5U_"
      },
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Import the .mp3 file\n",
        "mp3_file = AudioSegment.from_file(wav_fpath)\n",
        "\n",
        "# Export the .mp3 file as wav\n",
        "mp3_file.export('newSong.wav', format=\"wav\")\n",
        "wav_data, sample_rate1 = sf.read('newSong.wav', dtype=np.int16)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA_L-n_EB7Z-"
      },
      "source": [
        "from scipy import signal\n",
        "def ensure_sample_rate(original_sample_rate, waveform,\n",
        "                       desired_sample_rate=16000):\n",
        "  \"\"\"Resample waveform if required.\"\"\"\n",
        "  if original_sample_rate != desired_sample_rate:\n",
        "    desired_length = int(round(float(len(waveform)) /\n",
        "                               original_sample_rate * desired_sample_rate))\n",
        "    waveform = signal.resample(waveform, desired_length)\n",
        "  return desired_sample_rate, waveform"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TNbPghiDDSv"
      },
      "source": [
        "YAMNET model load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhswBUHBB-P5"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "# Load the model.\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGQNMTwcExFn"
      },
      "source": [
        "Load saved 'classifier' model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNRo102fCCfC"
      },
      "source": [
        "import pickle\n",
        "clf= pickle.load(open('/content/drive/MyDrive/model_binary.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od6cSgJ7DJ5u"
      },
      "source": [
        "Get features from YAMnet for test input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMqqfa5lCFs7"
      },
      "source": [
        "  sample_rate, wav_data = ensure_sample_rate(sample_rate1, recov)\n",
        "  duration = len(wav_data)/sample_rate\n",
        "  waveform = wav_data / tf.int16.max\n",
        "  scores, embeddings, spectrogram = model(waveform)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiTIrbjGImlS"
      },
      "source": [
        "from joblib import dump, load\n",
        "pca=load('/content/drive/MyDrive/pca_model.joblib','r')"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3IWX-ezCI1I"
      },
      "source": [
        "spec=np.array(embeddings)\n",
        "out=pca.fit_transform(np.transpose(spec))\n",
        "out=np.reshape(out,(1,out.shape[0]*out.shape[1]))"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0KMKuY2DRU3"
      },
      "source": [
        "Predict on the classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylynXwCGCQAg",
        "outputId": "99fc6fee-2420-4ec6-cb7b-d0c1fae664bc"
      },
      "source": [
        "speak=clf.predict(out)\n",
        "if speak==[0]:\n",
        "  print('One speaker')\n",
        "else:\n",
        "  print(\"Multiple speaker\")"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiple speaker\n"
          ]
        }
      ]
    }
  ]
}